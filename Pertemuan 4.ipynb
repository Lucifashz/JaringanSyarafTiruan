{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lCybrNeZ4ay",
        "outputId": "3b2b5a7b-6bac-4907-dade-7a455adc1d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim #library gensim untuk model word2vac"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import gensim"
      ],
      "metadata": {
        "id": "rooUD0T8Z9Cf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://goo.gl/bXfSDa\n",
        "#!wget https://goo.gl/WXmhSf\n",
        "#!wget https://goo.gl/RXEdAk\n",
        "!wget https://www.dropbox.com/s/exe4yv8rfi6hclf/ind_news_2020_1M.tar.gz?dl=1 -O corpus.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAWjdb7JZ9E7",
        "outputId": "8794b25f-04f0-4ef8-d484-450c69e06689"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-15 12:35:46--  https://www.dropbox.com/s/exe4yv8rfi6hclf/ind_news_2020_1M.tar.gz?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/exe4yv8rfi6hclf/ind_news_2020_1M.tar.gz [following]\n",
            "--2023-01-15 12:35:46--  https://www.dropbox.com/s/dl/exe4yv8rfi6hclf/ind_news_2020_1M.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucec557bcdcd34cda94ecd10c7c3.dl.dropboxusercontent.com/cd/0/get/B0knx1a3iRriE2sEY963QuzOH0VMo2ddfQvasOjPyny3h6N4thQDmV0SEk1y2siH1xrB6z6kwnCIXTgXAT8cHrHq0AAGjpu4DmNhPMesRfHC1KAznMXPK5wh8DMkENIi3Or1wDyaS3HlXKBzQ6Zq0eJbxi9HSF5FvcCBTUOZFQUBbnpUeT2fszZ7U56d1JvZ9_I/file?dl=1# [following]\n",
            "--2023-01-15 12:35:46--  https://ucec557bcdcd34cda94ecd10c7c3.dl.dropboxusercontent.com/cd/0/get/B0knx1a3iRriE2sEY963QuzOH0VMo2ddfQvasOjPyny3h6N4thQDmV0SEk1y2siH1xrB6z6kwnCIXTgXAT8cHrHq0AAGjpu4DmNhPMesRfHC1KAznMXPK5wh8DMkENIi3Or1wDyaS3HlXKBzQ6Zq0eJbxi9HSF5FvcCBTUOZFQUBbnpUeT2fszZ7U56d1JvZ9_I/file?dl=1\n",
            "Resolving ucec557bcdcd34cda94ecd10c7c3.dl.dropboxusercontent.com (ucec557bcdcd34cda94ecd10c7c3.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to ucec557bcdcd34cda94ecd10c7c3.dl.dropboxusercontent.com (ucec557bcdcd34cda94ecd10c7c3.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 224376751 (214M) [application/binary]\n",
            "Saving to: ‘corpus.tar.gz’\n",
            "\n",
            "corpus.tar.gz       100%[===================>] 213.98M   154MB/s    in 1.4s    \n",
            "\n",
            "2023-01-15 12:35:48 (154 MB/s) - ‘corpus.tar.gz’ saved [224376751/224376751]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nama folder sesuai dengan folder yang didownload\n",
        "#bXfSDa             100%[===================>] 213.98M   154MB/s    in 1.4s\n",
        "\n",
        "#!tar -xzvf bXfSDa\n",
        "#!tar -xzvf WXmhSf\n",
        "#!tar -xzvf RXEdAk\n",
        "!tar -xzvf corpus.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UYoRLCgZ9Ho",
        "outputId": "9383b72e-4e77-432e-db45-0fe59a469f19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ind_news_2020_1M/\n",
            "ind_news_2020_1M/ind_news_2020_1M-sentences.txt\n",
            "ind_news_2020_1M/ind_news_2020_1M-sources.txt\n",
            "ind_news_2020_1M/ind_news_2020_1M-words.txt\n",
            "ind_news_2020_1M/ind_news_2020_1M-inv_so.txt\n",
            "ind_news_2020_1M/ind_news_2020_1M-inv_w.txt\n",
            "ind_news_2020_1M/ind_news_2020_1M-import.sql\n",
            "ind_news_2020_1M/ind_news_2020_1M-co_s.txt\n",
            "ind_news_2020_1M/ind_news_2020_1M-co_n.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!car ind_news_2020_1M-sentences.txt"
      ],
      "metadata": {
        "id": "nxVSkkyHZ9J2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpora = gensim.corpora.TextCorpus('ind_news_2020_1M/ind_news_2020_1M-sentences.txt')\n",
        "article_count = 0\n",
        "with io.open('corpus.txt', 'a') as wiki_text:\n",
        "  for text in corpora.get_texts():\n",
        "\n",
        "    wiki_text.write(\" \".join(map(str, text)) + '\\n')\n",
        "    article_count += 1\n",
        "\n",
        "    if article_count % 10000 == 0:\n",
        "      print('{} article processed'.format(article_count))\n",
        "\n",
        "  print('total: {} articles'.format(article_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV2spaHaZ9Od",
        "outputId": "478e59b0-f1c4-4e56-f15d-45ebfd8028fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 article processed\n",
            "20000 article processed\n",
            "30000 article processed\n",
            "40000 article processed\n",
            "50000 article processed\n",
            "60000 article processed\n",
            "70000 article processed\n",
            "80000 article processed\n",
            "90000 article processed\n",
            "100000 article processed\n",
            "110000 article processed\n",
            "120000 article processed\n",
            "130000 article processed\n",
            "140000 article processed\n",
            "150000 article processed\n",
            "160000 article processed\n",
            "170000 article processed\n",
            "180000 article processed\n",
            "190000 article processed\n",
            "200000 article processed\n",
            "210000 article processed\n",
            "220000 article processed\n",
            "230000 article processed\n",
            "240000 article processed\n",
            "250000 article processed\n",
            "260000 article processed\n",
            "270000 article processed\n",
            "280000 article processed\n",
            "290000 article processed\n",
            "300000 article processed\n",
            "310000 article processed\n",
            "320000 article processed\n",
            "330000 article processed\n",
            "340000 article processed\n",
            "350000 article processed\n",
            "360000 article processed\n",
            "370000 article processed\n",
            "380000 article processed\n",
            "390000 article processed\n",
            "400000 article processed\n",
            "410000 article processed\n",
            "420000 article processed\n",
            "430000 article processed\n",
            "440000 article processed\n",
            "450000 article processed\n",
            "460000 article processed\n",
            "470000 article processed\n",
            "480000 article processed\n",
            "490000 article processed\n",
            "500000 article processed\n",
            "510000 article processed\n",
            "520000 article processed\n",
            "530000 article processed\n",
            "540000 article processed\n",
            "550000 article processed\n",
            "560000 article processed\n",
            "570000 article processed\n",
            "580000 article processed\n",
            "590000 article processed\n",
            "600000 article processed\n",
            "610000 article processed\n",
            "620000 article processed\n",
            "630000 article processed\n",
            "640000 article processed\n",
            "650000 article processed\n",
            "660000 article processed\n",
            "670000 article processed\n",
            "680000 article processed\n",
            "690000 article processed\n",
            "700000 article processed\n",
            "710000 article processed\n",
            "720000 article processed\n",
            "730000 article processed\n",
            "740000 article processed\n",
            "750000 article processed\n",
            "760000 article processed\n",
            "770000 article processed\n",
            "780000 article processed\n",
            "790000 article processed\n",
            "800000 article processed\n",
            "810000 article processed\n",
            "820000 article processed\n",
            "830000 article processed\n",
            "840000 article processed\n",
            "850000 article processed\n",
            "860000 article processed\n",
            "870000 article processed\n",
            "880000 article processed\n",
            "890000 article processed\n",
            "900000 article processed\n",
            "910000 article processed\n",
            "920000 article processed\n",
            "930000 article processed\n",
            "940000 article processed\n",
            "950000 article processed\n",
            "960000 article processed\n",
            "970000 article processed\n",
            "980000 article processed\n",
            "990000 article processed\n",
            "1000000 article processed\n",
            "total: 1000000 articles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import multiprocessing\n",
        "from datetime import timedelta\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "start_time = time.time()\n",
        "print('Training Word2Vec Model...')\n",
        "sentences = word2vec.LineSentence('corpus.txt')\n",
        "id_w2v = word2vec.Word2Vec(sentences, size=300, workers=16)\n",
        "id_w2v.save('model_word2vec_300_model')\n",
        "finish_time = time.time()\n",
        "\n",
        "print('Finished. Elapsed time: {}'\n",
        "      .format(timedelta(seconds=finish_time-start_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4oDS6tjZ9RA",
        "outputId": "80480fa4-22ea-40eb-cc5c-3c6e6842ba9d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Word2Vec Model...\n",
            "Finished. Elapsed time: 0:04:04.533179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_w2v.wv.similarity('wanita', 'pria')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYkCCtaRZ9Tu",
        "outputId": "0a38ddf5-c7c3-4eff-d163-fbdb3a4f2794"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8557649"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_w2v.wv.most_similar('anjing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbha7ntpZ9WH",
        "outputId": "917f9161-7764-448d-bf29-19b276ae7db2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kucing', 0.8617904186248779),\n",
              " ('seekor', 0.79078209400177),\n",
              " ('monyet', 0.7301870584487915),\n",
              " ('peliharaannya', 0.7255553007125854),\n",
              " ('ular', 0.7222533822059631),\n",
              " ('reptil', 0.690906822681427),\n",
              " ('burung', 0.6878210306167603),\n",
              " ('serangga', 0.6855883598327637),\n",
              " ('kambing', 0.6849707365036011),\n",
              " ('hewan', 0.6819730997085571)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_w2v.wv.most_similar(positive=['wanita', 'raja'], negative=['pria'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5WXDSCUZ9YT",
        "outputId": "4c74863e-0e95-40d6-d06d-ac464eb79750"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ratu', 0.7338839769363403),\n",
              " ('kaisar', 0.61744225025177),\n",
              " ('pewaris', 0.5955592393875122),\n",
              " ('kristen', 0.590506911277771),\n",
              " ('kesultanan', 0.5771392583847046),\n",
              " ('tahta', 0.5735514760017395),\n",
              " ('sapta', 0.5722467303276062),\n",
              " ('elizabeth', 0.5680570602416992),\n",
              " ('kerajaan', 0.567563533782959),\n",
              " ('permaisuri', 0.5667973160743713)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_w2v.wv.doesnt_match(\"laki wanita perempuan pria banci\".split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "VEWavMeQZ9dQ",
        "outputId": "86efe53a-7926-4dd8-bea8-fe1990aefb48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:vectors for words {'banci'} are not present in the model, ignoring these words\n",
            "/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'laki'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_w2v.wv.most_similar('mereka')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_M9CF4XZ9f3",
        "outputId": "32ca7975-dbcc-4500-bb16-ae16a206f284"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('anda', 0.6604316830635071),\n",
              " ('kalian', 0.6353877186775208),\n",
              " ('kamu', 0.6331143379211426),\n",
              " ('dia', 0.6054595708847046),\n",
              " ('kami', 0.6040409803390503),\n",
              " ('seseorang', 0.5798472762107849),\n",
              " ('keduanya', 0.5633684396743774),\n",
              " ('kita', 0.534696638584137),\n",
              " ('liverpool', 0.5341835618019104),\n",
              " ('dirinya', 0.5144944190979004)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}